{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gustavocac/rsna_handson/blob/master/COVID_fast_AI.ipynb\" target=\"_parent\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uH4B_VCqjKy3"
   },
   "source": [
    "![image](https://github.com/gustavocac/COVID_hanson/blob/master/cdc-k0KRNtqcjfw-unsplash.jpg?raw=true)\n",
    "Photo by CDC on Unsplash\n",
    "\n",
    "\n",
    "# COVID 2019 \n",
    "\n",
    "# Hands-on - Deep Learning for COVID Detection on CT \n",
    "\n",
    "\n",
    "\n",
    "**Developed by:**\n",
    "Gustavo C. A. Corradi\n",
    "\n",
    "Originally Branched and adapted from:\n",
    "\n",
    "https://colab.research.google.com/github/gustavocac/rsna_handson/blob/master/RSNA_for_Non_Coders_final_version.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbAUq1KmksS9"
   },
   "source": [
    "All the process will be demonstrated with Python 3 running on Google Colaboratory. \n",
    "Please make sure you have GPU enabled under notebook settings before you proceed.\n",
    "\n",
    "**There are 3 training sets:**\n",
    "\n",
    "- Dataset 0 comprises 60 normal and 6 COVID CT images.\n",
    "\n",
    "- Dataset 1 comprises 33 normal and 33 COVID CT images.\n",
    "\n",
    "- Dataset 2 comprises 60 normal and 60 COVID CT images.\n",
    "\n",
    "Validation and Test sets have 20 normal and 20 COVID, except for dataset 0 (20 normal and 2 COVID).\n",
    "\n",
    "For each specific task we will import specific libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwFwbMGIuHsH"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_hkRJ8W-6xF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-vis\n",
      "  Downloading https://files.pythonhosted.org/packages/70/b6/585f1c100b3ee5b8a12cf603c21a9a1f11010eaf634b4d5d73346e7b0c14/keras_vis-0.4.1-py2.py3-none-any.whl\n",
      "Collecting six (from keras-vis)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/6b/7f62017e3f0b32438dd90bdc1ff0b7b1448b6cb04a1ed84f37b6de95cd7b/h5py-2.10.0-cp37-cp37m-win_amd64.whl (2.5MB)\n",
      "Collecting keras (from keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "Collecting scikit-image (from keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/5a/abd74bd5ce791e2ab0b6fd88b144c42dbc88b3b1d963147417d0e163684b/scikit_image-0.16.2-cp37-cp37m-win_amd64.whl (25.7MB)\n",
      "Collecting matplotlib (from keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/4d/8a2c06cb69935bb762738a8b9d5f8ce2a66be5a1410787839b71e146f000/matplotlib-3.2.1-cp37-cp37m-win_amd64.whl (9.2MB)\n",
      "Collecting numpy>=1.7 (from h5py->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/50/cd3e12bf41ac273702882610fd43bd765b8d2b99baf4295b00578fd69323/numpy-1.18.2-cp37-cp37m-win_amd64.whl (12.8MB)\n",
      "Collecting keras-applications>=1.0.6 (from keras->keras-vis)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting scipy>=0.14 (from keras->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/51/046cbc61c7607e5ecead6ff1a9453fba5e7e47a5ea8d608cc7036586a5ef/scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9MB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras->keras-vis)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from keras->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/aa/1a7ac452c52b93ab759d0b5b81c901ea122d95a5abf429decc660a44a2f1/PyYAML-5.3.1-cp37-cp37m-win_amd64.whl (216kB)\n",
      "Collecting networkx>=2.0 (from scikit-image->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
      "Collecting imageio>=2.3.0 (from scikit-image->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/2b/9dd19644f871b10f7e32eb2dbd6b45149c350b4d5f2893e091b882e03ab7/imageio-2.8.0-py3-none-any.whl (3.3MB)\n",
      "Collecting PyWavelets>=0.4.0 (from scikit-image->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/e1/c3d97d145ce3377c53f1feca5742ca2b2a38c34dcbe301e2212de3cc654d/PyWavelets-1.1.1-cp37-cp37m-win_amd64.whl (4.2MB)\n",
      "Collecting pillow>=4.3.0 (from scikit-image->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/9c/04297251a6e38b8506a4fcee17a1f16765a12ab8d805f9fd9e0fda424fec/Pillow-7.1.1-cp37-cp37m-win_amd64.whl (2.0MB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/e5/d8bd2d063da3b6761270f29038d2bb9785c88ff385009bf61589cde6e6ef/kiwisolver-1.2.0-cp37-none-win_amd64.whl (57kB)\n",
      "Collecting python-dateutil>=2.1 (from matplotlib->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting decorator>=4.3.0 (from networkx>=2.0->scikit-image->keras-vis)\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl\n",
      "Installing collected packages: six, numpy, h5py, keras-applications, scipy, keras-preprocessing, pyyaml, keras, decorator, networkx, pillow, imageio, PyWavelets, pyparsing, cycler, kiwisolver, python-dateutil, matplotlib, scikit-image, keras-vis\n",
      "Successfully installed PyWavelets-1.1.1 cycler-0.10.0 decorator-4.4.2 h5py-2.10.0 imageio-2.8.0 keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 keras-vis-0.4.1 kiwisolver-1.2.0 matplotlib-3.2.1 networkx-2.4 numpy-1.18.2 pillow-7.1.1 pyparsing-2.4.7 python-dateutil-2.8.1 pyyaml-5.3.1 scikit-image-0.16.2 scipy-1.4.1 six-1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\GUSTA\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts imageio_download_bin.exe and imageio_remove_bin.exe are installed in 'C:\\Users\\GUSTA\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script skivi.exe is installed in 'C:\\Users\\GUSTA\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imgaug==0.2.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/60/a06a48d85a7e9062f5870347a3e3e953da30b37928d43b380c949bca458a/imgaug-0.2.5.tar.gz (562kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from imgaug==0.2.5) (1.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from imgaug==0.2.5) (0.16.2)\n",
      "Requirement already satisfied: numpy>=1.7.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from imgaug==0.2.5) (1.18.2)\n",
      "Requirement already satisfied: six in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from imgaug==0.2.5) (1.14.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.8.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (7.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (3.2.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.5) (4.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.4.7)\n",
      "Installing collected packages: imgaug\n",
      "  Running setup.py install for imgaug: started\n",
      "    Running setup.py install for imgaug: finished with status 'done'\n",
      "Successfully installed imgaug-0.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/58/f0/d00c0e01e077da883f030af3ff5ce653a0e9e4786f83faa89a6e18c98612/scipy-1.2.1-cp37-cp37m-win_amd64.whl (30.0MB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\gusta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.7_qbz5n2kfra8p0\\localcache\\local-packages\\python37\\site-packages (from scipy==1.2.1) (1.18.2)\n",
      "Installing collected packages: scipy\n",
      "  Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "Successfully installed scipy-1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/74/dbed754c0abd63768d3a7a7b472da35b08ac442cf87d73d5850a6f32391e/graphviz-0.13.2-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling matplotlib-3.1.1:\n",
      "  Successfully uninstalled matplotlib-3.1.1\n",
      "Collecting matplotlib==3.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/52/17dbb82ca36937dd4d0027fe1945c3c78bdb465b4736903d0904b7f595ad/matplotlib-3.1.0-cp37-cp37m-win_amd64.whl (9.1MB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib==3.1.0) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib==3.1.0) (1.16.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib==3.1.0) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib==3.1.0) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib==3.1.0) (0.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib==3.1.0) (41.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib==3.1.0) (1.12.0)\n",
      "Installing collected packages: matplotlib\n",
      "Successfully installed matplotlib-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#@title System Setup - After installation the the system will restart. This will generate an error message which is expected. Just ignore it :) {display-mode: \"form\"}\n",
    "#Installing dependencies\n",
    "\n",
    "import sys, os\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "#default_stdout = sys.stdout\n",
    "#file_handle = open(os.devnull, \"w\")\n",
    "#sys.stderr = open(os.devnull, \"w\")\n",
    "\n",
    "#sys.stdout = file_handle\n",
    "\n",
    "!pip3 install keras-vis\n",
    "!pip3 install imgaug==0.2.5\n",
    "!pip3 install scipy==1.2.1\n",
    "!pip3 install graphviz\n",
    "!pip uninstall matplotlib --yes\n",
    "!pip install matplotlib==3.1.0\n",
    "!pip install academictorrents\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "#clear_output()\n",
    "#os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9dmrWVwRbDR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/lprevedello/RSNA-2019-Hands-on/blob/master/folders.png?raw=true\" width=\"900\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Dataset Download from Github https://github.com/ieee8023/covid-chestxray-dataset/blob/master/ {display-mode: \"form\"}\n",
    "\n",
    "import sys, os\n",
    "import academictorrents as at\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "default_stdout = sys.stdout\n",
    "file_handle = open(os.devnull, \"w\")\n",
    "sys.stderr = open(os.devnull, \"w\")\n",
    "\n",
    "sys.stdout = file_handle\n",
    "\n",
    "#@title\n",
    "#First of all, we are going to download the zip files with the images to this instance of Google's Colaboratory\n",
    "!cd \n",
    "!cd .Desktop/teste/positive\n",
    "!ls\n",
    "\n",
    "path_of_giant_dataset = at.get(\"323a0048d87ca79b68f12a6350a57776b6a3b7fb\") # Download mnist dataset\n",
    "!wget https://drive.google.com/file/d/1SJoMelgRqb0EuqlTuq6dxBWf2j9Kno8S/view\n",
    "!wget https://github.com/ieee8023/covid-chestxray-dataset   \n",
    "!wget https://github.com/kitamura-felipe/deeplearning_head_ct_demo/blob/master/33_33.zip?raw=true\n",
    "!wget https://github.com/kitamura-felipe/deeplearning_head_ct_demo/blob/master/60_6.zip?raw=true\n",
    "  \n",
    "  #@title\n",
    "#Let's unzip them\n",
    "\n",
    "\n",
    "\n",
    "!unzip -o Allcases.zip?raw=true -d /Cases\n",
    "!unzip -o 33_33.zip?raw=true -d /Cases\n",
    "!unzip -o 60_6.zip?raw=true -d /Cases\n",
    "\n",
    "\n",
    "#print ('\\033[1m' + 'All images downloaded. Please check folder contents under \"Files\" on the left!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "LhGUx-McKJ1M"
   },
   "outputs": [],
   "source": [
    "#@title Reset for next experiment\n",
    "import os\n",
    "os.kill(os.getpid(), 9)\n",
    "import sys, os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrsQG6zJHI5F"
   },
   "outputs": [],
   "source": [
    "#@title Dataset Selection and Preprocessing {display-mode: \"form\"}\n",
    "import os\n",
    "\n",
    "Dataset = \"60/6\" #@param [\"60/6\", \"33/33\", \"60/60\"]\n",
    "Augmentation = \"off\" #@param [\"off\", \"on\", \"custom\"]\n",
    "angle = 359 #@param {type:\"slider\", min:0, max:359, step:1}\n",
    "zoom = 1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "width_shift_range = 1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "height_shift_range = 1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "shear_range = 1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "horizontal_flip = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Importing libraries for arrays (NumPy), Pre-processing (Keras) and plotting images (Matplotlib)\n",
    "%tensorflow_version 1.x\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# It is important to set a random seed in order to have reproducbility of training results between different users\n",
    "# SET ALL THE SEEDS\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(123)\n",
    "os.environ['PYTHONHASHSEED'] = '123'\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "# Dimensions which our images will be resized for the input. All of them must have the same size\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# We split the data between 60/10/30% for training/validation/test sets \n",
    "# We choose which directories must be used\n",
    "\n",
    "validation_data_dir = '/Cases/All cases/Validation/'\n",
    "nb_validation_samples = 40\n",
    "\n",
    "test_data_dir = '/Cases/All cases/Test/'\n",
    "nb_test_samples = 40\n",
    "\n",
    "if Dataset == '60/6':\n",
    "  train_data_dir = '/Cases/60+6/Training/'\n",
    "  nb_train_samples = 66\n",
    "  test_data_dir = '/Cases/60+6/Test/'\n",
    "  nb_test_samples = 40\n",
    "  validation_data_dir = '/Cases/60+6/Validation/'\n",
    "  nb_validation_samples = 40\n",
    "elif Dataset == '33/33':\n",
    "  train_data_dir = '/Cases/33+33/Training/'\n",
    "  nb_train_samples = 66\n",
    "else:\n",
    "  train_data_dir = '/Cases/All cases/Training/'\n",
    "  nb_train_samples = 120\n",
    "\n",
    "ds_size = {\n",
    "    \"Train_Hematoma\": len(glob(train_data_dir + \"Hematoma/*\")),\n",
    "    \"Train_Normal\": len(glob(train_data_dir + \"Normal/*\")),\n",
    "    \"Val_Hematoma\": len(glob(validation_data_dir + \"Hematoma/*\")),\n",
    "    \"Val_Normal\": len(glob(validation_data_dir + \"Normal/*\")),\n",
    "    \"Test_Hematoma\": len(glob(test_data_dir + \"Hematoma/*\")),\n",
    "    \"Test_Normal\": len(glob(test_data_dir + \"Normal/*\")),\n",
    "}\n",
    "\n",
    "# For generator we need to give these two hyperparameters\n",
    "epochs = 40\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# This is the augmentation configuration we will use for training\n",
    "dataaug = Augmentation\n",
    "\n",
    "if dataaug == \"off\":\n",
    "  print(\"Data Augmentation OFF\")\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255) # normalization\n",
    "elif dataaug == \"on\":\n",
    "  print(\"Data Augmentation ON\")\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255, # normalization\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      rotation_range=20,\n",
    "      fill_mode=\"constant\",\n",
    "      horizontal_flip=True)  \n",
    "else:\n",
    "  print(\"Data Augmentation Custom\")\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255, # normalization\n",
    "      width_shift_range=width_shift_range,\n",
    "      height_shift_range=height_shift_range,\n",
    "      shear_range=shear_range,\n",
    "      fill_mode=\"constant\",\n",
    "      zoom_range=zoom, \n",
    "      rotation_range=angle,\n",
    "      horizontal_flip=horizontal_flip)\n",
    "\n",
    "# This is the augmentation configuration we will use for validation:\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255) # normalization\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) # normalization\n",
    "\n",
    "print(\"Training set:\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "print(\"Validation set:\")\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "print(\"Test set:\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=nb_test_samples,\n",
    "    class_mode='binary', shuffle = False)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#Let's plot the class frequencies\n",
    "\n",
    "print ('\\033[1m' + '\\r\\n          Training Set Distribution')\n",
    "plt.figure()\n",
    "plt.bar([0, 1], [ds_size['Train_Hematoma'], ds_size['Train_Normal']], color=['red', 'blue'])\n",
    "plt.xticks([0, 1], ('Hematoma', 'Normal'))\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + '\\r\\n          Validation Set Distribution')\n",
    "plt.figure()\n",
    "plt.bar([0, 1], [ds_size['Val_Hematoma'], ds_size['Val_Normal']], color=['red', 'blue'])\n",
    "plt.xticks([0, 1], ('Hematoma', 'Normal'))\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + '\\r\\n          Test Set Distribution')\n",
    "plt.figure()\n",
    "plt.bar([0, 1], [ds_size['Test_Hematoma'], ds_size['Test_Normal']], color=['red', 'blue'])\n",
    "plt.xticks([0, 1], ('Hematoma', 'Normal'))\n",
    "plt.show()\n",
    "\n",
    "# Let's plot the first 4 generator outputs, defining the positive cases as Label = True and negatives as Label = False \n",
    "\n",
    "print ('\\033[1m' + '\\r\\nNow let\\'s see some examples\\r\\n')\n",
    "\n",
    "x,y = train_generator.next()\n",
    "\n",
    "labley = y==0\n",
    "#shape = x.shape\n",
    "#print (shape)\n",
    "#for i in range(0, 8):\n",
    "#  plt.subplot(240 + 1 + i).grid(False)\n",
    "#  plt.imshow(x[i], cmap=plt.get_cmap('gray'))\n",
    "#  plt.title(\"\\nLable:{}\".format(labley[i]))\n",
    "#  plt.axis('off')\n",
    "\n",
    "start_idx = 0\n",
    "fig, ax = plt.subplots(2,5, figsize=(15,8))\n",
    "for j in range(0,2): \n",
    "  for i in range(0,5):\n",
    "     ax[j][i].xaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].yaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].imshow(x[start_idx], cmap='gray')\n",
    "     ax[j][i].set_title(\"Index: {} \\nLabel: {}\".format(start_idx, 'Hematoma' if y[start_idx]==0 else 'Normal'))\n",
    "     start_idx +=1\n",
    "plt.show()\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZr5PnzuynjJ"
   },
   "source": [
    "<center> <img src=\"https://github.com/igorafaelms/rsna_handson/blob/master/transfer_learning.png?raw=true\"> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zi3uEzBZHr0w"
   },
   "outputs": [],
   "source": [
    "#@title Setting Neural Net {display-mode: \"form\"}\n",
    "\n",
    "transfer_learning = \"VGG16+ImageNet\" #@param [\"None\", \"VGG16+ImageNet\"]\n",
    "\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "# We can improve our results using transfer learning\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "if transfer_learning==\"None\":\n",
    "  base_model = VGG16(weights=None, include_top=False, input_shape=(img_width, img_height, 3))\n",
    "else:\n",
    "  base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "# Let's edit the last layers of VGG16 to use it in our solution\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "clear_output()\n",
    "from keras.models import Model\n",
    "clear_output()\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "clear_output()\n",
    "from keras import optimizers\n",
    "clear_output()\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Only for version 2\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# And a logistic layer\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "SIIM_Net= Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# We can try using a different optimizer as well\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "SIIM_Net.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpWTo4nSIPDy"
   },
   "outputs": [],
   "source": [
    "#@title Training and Validation {display-mode: \"form\"}\n",
    "epochs = 20 #@param {type:\"slider\", min:5, max:80, step:1}\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "\n",
    "# Time to train it\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='Best_model.hdf5', monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "hist = SIIM_Net.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size,\n",
    "            callbacks=[checkpointer])\n",
    "\n",
    "#Plotting the loss function\n",
    "\n",
    "plt.plot(hist.history['loss'], 'b-', label='train loss')\n",
    "plt.plot(hist.history['val_loss'], 'r-', label='val loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(hist.history['acc'], 'b-', label='train accuracy')\n",
    "plt.plot(hist.history['val_acc'], 'r-', label='val accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('\\033[1m' + \"Best Validation Accuracy: {:.2f}%\".format(hist.history['val_acc'][np.argmin(hist.history['val_loss'])]*100.))\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5jVTnNKJfyj"
   },
   "outputs": [],
   "source": [
    "#@title Algorithm Performance (test set) - Score Histogram per Class { display-mode: \"form\" }\n",
    "\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "\n",
    "from keras.models import load_model\n",
    "from tabulate import tabulate\n",
    "\n",
    "#Loading the best model\n",
    "\n",
    "best_model = load_model('Best_model.hdf5')\n",
    "\n",
    "X, Y = test_generator.next() # Get the X (images) and Y (labels) of the test set\n",
    "\n",
    "labels_pred = best_model.predict(X) #predict the output from X\n",
    "\n",
    "labels_test = Y\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "Y_neg = (1-labels_pred[labels_test == 1])\n",
    "\n",
    "Y_pos = (1-labels_pred[labels_test == 0])\n",
    "headers = [\"Normal\", \"Hematoma\"]\n",
    "print(tabulate([[Y_neg,Y_pos]],headers,tablefmt=\"orgtbl\"))\n",
    "\n",
    "bins = np.linspace(0, 1, 100)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(Y_neg, bins, alpha=0.4, label='Normal', color='b')\n",
    "plt.hist(Y_pos, bins, alpha=0.4, label='Hematoma', color='r')\n",
    "plt.legend(loc='upper center')\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJNi_Gts8dty"
   },
   "outputs": [],
   "source": [
    "#@title Algorithm Performance (test set) - 2 x 2 table { display-mode: \"form\" }\n",
    "threshold = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "threshold = 1-threshold\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#Loading the best model\n",
    "\n",
    "best_model = load_model('Best_model.hdf5')\n",
    "\n",
    "\n",
    "# Defining a function to plot a confusion matrix.\n",
    "\n",
    "# from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = '2x2 table'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='Ground Truth',\n",
    "           xlabel='Predicted')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[1]):\n",
    "        for j in range(cm.shape[0]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "X, Y = test_generator.next() # Get the X (images) and Y (labels) of the test set\n",
    "\n",
    "labels_pred = best_model.predict(X) #predict the output from X\n",
    "\n",
    "#labels_pred = labels_pred > labels_pred.mean() #predictions greater than mean are set to 1, those lesser than or equal to mean are set to 0.\n",
    "\n",
    "labels_pred = labels_pred >= threshold\n",
    "\n",
    "labels_test = Y\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(labels_test, labels_pred.astype('int'), classes=['Hematoma','Normal'], normalize=False,\n",
    "                      title='Confusion Matrix (Counts)')\n",
    "\n",
    "accuracy = metrics.accuracy_score(labels_test, labels_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100.))\n",
    "\n",
    "#print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-z04WjMXWLE"
   },
   "outputs": [],
   "source": [
    "#@title Algorithm Performance (test set) - ROC Curve {display-mode: \"form\"}\n",
    "\n",
    "threshold = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "threshold = 1-threshold\n",
    "\n",
    "#Plotting the ROC curve with the AUC\n",
    "\n",
    "labels_pred = best_model.predict(X) # predict again to get the original sigmoid output [0,1]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels_test, labels_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.plot(fpr[np.argmin(np.abs(thresholds-threshold))],tpr[np.argmin(np.abs(thresholds-threshold))], 'o', color='red')\n",
    "\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#labels_pred = labels_pred > labels_pred.mean() #predictions greater than mean are set to 1, those lesser than or equal to mean are set to 0.\n",
    "\n",
    "labels_pred = labels_pred >= threshold\n",
    "\n",
    "f1_score = metrics.f1_score(labels_test, labels_pred, labels=None, pos_label=0, average='binary', sample_weight=None)\n",
    "\n",
    "accuracy = metrics.accuracy_score(labels_test, labels_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100.))\n",
    "\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score))\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7v2NUvMT7aib"
   },
   "outputs": [],
   "source": [
    "#@title Test Evaluation - Prediction on sampled images {display-mode: \"form\"}\n",
    "threshold = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "threshold = 1-threshold\n",
    "\n",
    "# Finally, we can use the test set for predictions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test_data_dir = '/Cases/All cases/Test/' # location of test dataset\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "         rescale=1./255)       # normalize pixel values to [0,1]\n",
    "\n",
    "# Preparing test set images for prediction\n",
    "\n",
    "itr = test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=40,\n",
    "    shuffle='False',\n",
    "    class_mode='binary')\n",
    "batch_x, batch_y = itr.next()\n",
    "\n",
    "print('Test Accuracy: {:.2f}%'.format(100.*best_model.evaluate(batch_x, batch_y, verbose=0)[1]))\n",
    "\n",
    "\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "#prediction1 = np.round(best_model.predict(batch_x, verbose=1))==0\n",
    "prediction = best_model.predict(batch_x, verbose=1)\n",
    "\n",
    "start_idx = randrange(batch_x.shape[0]-10) \n",
    "fig, ax = plt.subplots(2,5, figsize=(15,8))\n",
    "for j in range(0,2): \n",
    "  for i in range(0,5):\n",
    "     ax[j][i].xaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].yaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].imshow(batch_x[start_idx], cmap='gray')\n",
    "     ax[j][i].set_title(\"Index: {} \\nPrediction: {} \\nValue: {:.2f}\".format(start_idx, 'Hematoma' if prediction[start_idx]<threshold else 'Normal', 1-prediction[start_idx][0]))\n",
    "     start_idx +=1\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JU3kUp6ccpVV"
   },
   "outputs": [],
   "source": [
    "#@title Visualization - Saliency Maps {display-mode: \"form\"}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing visualization tools\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.layers import Input\n",
    "from keras import activations\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import initializers\n",
    "from keras.models import Sequential, Model\n",
    "from vis.visualization import visualize_activation,visualize_saliency,overlay,visualize_cam\n",
    "from vis.utils import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import imagenet_utils\n",
    "import numpy as np\n",
    "\n",
    "layer_idx = utils.find_layer_idx(best_model, 'block5_conv3')\n",
    "print(\"Remove Activation from Last Layer\")\n",
    "# Swap softmax with linear\n",
    "best_model.layers[layer_idx].activation = activations.linear\n",
    "print(\"Done. Now Applying changes to the model ...\")\n",
    "activation2_model = utils.apply_modifications(best_model)\n",
    "\n",
    "#print(activation_model.summary())\n",
    "#im_files=[\"/All cases/Test/Hematoma/Test hematoma (1).png\",\"/All cases/Test/Normal/Test_normal (1).png\"]\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "import os\n",
    "\n",
    "dir_name='/Cases/All cases/Test/'\n",
    "im_files = test_generator.filenames\n",
    "for im_file in im_files[3:6]:\n",
    "    img1 = image.load_img(dir_name + im_file,target_size=(150,150))\n",
    "    img1 = image.img_to_array(img1)\n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img1 = preprocess_input(img1)\n",
    "    layer_idx = utils.find_layer_idx(activation2_model, 'block5_conv3')\n",
    "    heatmap = visualize_cam(activation2_model, layer_idx, filter_indices=range(activation2_model.layers[layer_idx].filters), seed_input=img1[0,:,:,:])\n",
    "    img_init=utils.load_img(dir_name + im_file,target_size=(150,150))\n",
    "    img_init = img_init[:,:,:3]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax1 = plt.subplot(1,3,1)\n",
    "    ax1.grid(False)\n",
    "    plt.imshow(img_init, cmap='gray')\n",
    "    ax2 = plt.subplot(1,3,2)\n",
    "    ax2.grid(False)\n",
    "    plt.imshow(heatmap)\n",
    "    ax3 = plt.subplot(1,3,3)\n",
    "    ax3.grid(False)\n",
    "    plt.imshow(overlay(img_init, heatmap))\n",
    "    plt.show()\n",
    "    \n",
    "#print ('\\n' + '\\033[1m' + 'Congratulations, you have completed the assignment!')\n",
    "\n",
    "#from IPython.display import HTML\n",
    "#HTML('<img src=\"https://media.giphy.com/media/cub3pntkz8muQ/giphy.gif\">')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "COVID_AI for Non-Coders w comments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
